{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "Toxic Comment Classification (LSTM + GRU & Fasttext + Glove).ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SaumilShah-7/Toxic-Comment-Classification-Challenge-Kaggle/blob/master/Toxic_Comment_Classification_(LSTM_%2B_GRU_%26_Fasttext_%2B_Glove).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "l1FBP09NzbSu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import gc\n",
        "from tqdm.notebook import tqdm_notebook as tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n",
        "from tensorflow.keras.preprocessing import text, sequence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0251CWaVzbS8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip -q -o '../input/jigsaw-toxic-comment-classification-challenge/train.csv.zip'\n",
        "!unzip -q -o '../input/jigsaw-toxic-comment-classification-challenge/test.csv.zip'\n",
        "!unzip -q -o '../input/jigsaw-toxic-comment-classification-challenge/test_labels.csv.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "9dVBtPTOzbTC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test  = pd.read_csv('test.csv')\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-qabs6ZezbTO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import regex as re\n",
        "!pip install Unidecode\n",
        "from unidecode import unidecode\n",
        "\n",
        "words_only = re.compile(r'[^A-Za-z\\']')\n",
        "def clean_text(x):\n",
        "    x_ascii = unidecode(x)\n",
        "    x_clean = words_only.sub(' ', x_ascii)\n",
        "    return x_clean\n",
        "\n",
        "train['clean_text'] = train['comment_text'].apply(lambda x: clean_text(x))\n",
        "test['clean_text'] = test['comment_text'].apply(lambda x: clean_text(x))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "wcsO-H7MzbTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train['comment_text'][1])\n",
        "print(train['clean_text'][1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fJIM-sa7zbTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['clean_text'].fillna('something')\n",
        "print(train[train.clean_text=='something'])\n",
        "test['clean_text'].fillna('something')\n",
        "print(test[test.clean_text=='something'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9WEPRq0ezbTj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_features = 250000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "iOeXJYLwzbTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = text.Tokenizer(num_words=max_features)\n",
        "t.fit_on_texts(list(train['clean_text'])+list(test['clean_text']))\n",
        "\n",
        "print(len(t.word_index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0IaJTfBmzbTx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_index = t.word_index\n",
        "word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "QESFT2QozbT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = t.texts_to_sequences(train['clean_text'])\n",
        "X_test = t.texts_to_sequences(test['clean_text'])\n",
        "\n",
        "print(X_train[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Uz3OdQKCzbT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "l = list(map(len, X_train))\n",
        "print('Min: %d, Mean: %d, Q3: %d, Max: %d' %(min(l), sum(l)/len(l), np.percentile(l, 75), max(l)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GYY5uOdQzbUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "toxicity_columns = list(train.columns)[2:-1]\n",
        "print(toxicity_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "5Bxj8PjjzbUM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 900\n",
        "x_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
        "\n",
        "y_train = train[toxicity_columns].values\n",
        "\n",
        "print(x_train.shape, y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(toxicity_columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Ap3cKON9zbUR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('x_train.npy', x_train)\n",
        "np.save('x_test.npy', x_test)\n",
        "np.save('y_train.npy', y_train)\n",
        "\n",
        "with open('word_index.pickle', 'wb') as handle:\n",
        "  pickle.dump(word_index, handle, protocol=pickle.HIGHEST_PROTOCOL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "MAknowAezbUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "del X_train, X_test, x_train, x_test, y_train, t, word_index, l\n",
        "\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "A7lEdGZ6zbUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ft_path = '../input/fasttext-crawl-300d-2m/crawl-300d-2M.vec'\n",
        "gl_path = '../input/glovetwitter27b100dtxt/glove.twitter.27B.200d.txt'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yBpcu5NkzbUo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_coefs(word,*arr):\n",
        "  return word, np.asarray(arr, dtype='float32')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": false,
        "trusted": true,
        "id": "EMQRgQD3zbUy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import gensim\n",
        "# model = gensim.models.KeyedVectors.load_word2vec_format(ft_path)\n",
        "\n",
        "# words = model.index2word\n",
        "\n",
        "# w_rank = {}\n",
        "# for i,word in enumerate(words):\n",
        "#     w_rank[word] = i\n",
        "\n",
        "# WORDS = w_rank\n",
        "\n",
        "# del model, words, w_rank\n",
        "# gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "gZj5PEA8zbU-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def words(text): return re.findall(r'\\w+', text.lower())\n",
        "\n",
        "# def P(word): \n",
        "#     \"Probability of `word`.\"\n",
        "#     # use inverse of rank as proxy\n",
        "#     # returns 0 if the word isn't in the dictionary\n",
        "#     return - WORDS.get(word, 0)\n",
        "\n",
        "# def correction(word): \n",
        "#     \"Most probable spelling correction for word.\"\n",
        "#     return max(candidates(word), key=P)\n",
        "\n",
        "# def candidates(word): \n",
        "#     \"Generate possible spelling corrections for word.\"\n",
        "#     return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
        "\n",
        "# def known(words): \n",
        "#     \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
        "#     return set(w for w in words if w in WORDS)\n",
        "\n",
        "# def edits1(word):\n",
        "#     \"All edits that are one edit away from `word`.\"\n",
        "#     letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
        "#     splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
        "#     deletes    = [L + R[1:]               for L, R in splits if R]\n",
        "#     transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
        "#     replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
        "#     inserts    = [L + c + R               for L, R in splits for c in letters]\n",
        "#     return set(deletes + transposes + replaces + inserts)\n",
        "\n",
        "# def edits2(word): \n",
        "#     \"All edits that are two edits away from `word`.\"\n",
        "#     return (e2 for e1 in edits1(word) for e2 in edits1(e1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "qERIHc8ZzbVH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('word_index.pickle', 'rb') as handle:\n",
        "    word_index = pickle.load(handle)\n",
        "\n",
        "nb_words = min(max_features, len(word_index))\n",
        "embed_size = 500\n",
        "word_process = re.compile(r'[^A-Za-z]')\n",
        "\n",
        "def getword(embeddings_keys, word):\n",
        "    if word in embeddings_keys:\n",
        "        return word\n",
        "    elif word.lower() in embeddings_keys:\n",
        "        return word.lower()\n",
        "    elif word.upper() in embeddings_keys:\n",
        "        return word.upper()\n",
        "    elif word.capitalize() in embeddings_keys:\n",
        "        return word.capitalize()\n",
        "    elif word_process.sub('', word) in embeddings_keys:\n",
        "        return word_process.sub('', word)\n",
        "    elif len(word)>1 and len(word)<=15:\n",
        "        x = correction(word)\n",
        "        if x in embeddings_keys:\n",
        "            return x\n",
        "\n",
        "    return None\n",
        "\n",
        "def build_matrix(nb_words, embed_size):\n",
        "    embeddings_ft = dict(get_coefs(*o.strip().split()) for o in open(ft_path))\n",
        "    embeddings_gl = dict(get_coefs(*o.strip().split()) for o in open(gl_path))\n",
        "    embeddings_keys_ft = list(embeddings_ft.keys())\n",
        "    \n",
        "    corrected = []\n",
        "    words_not_found = []\n",
        "    matrix = np.zeros((nb_words, embed_size))\n",
        "    \n",
        "    for word, i in tqdm(word_index.items()):\n",
        "        if i >= nb_words:\n",
        "            break\n",
        "        else:\n",
        "            word2 = getword(embeddings_keys_ft, word)\n",
        "            if word2 is not None:\n",
        "                matrix[i, :300] = embeddings_ft.get(word2)\n",
        "                if embeddings_gl.get(word2) is not None:\n",
        "                    matrix[i, 300:] = embeddings_gl.get(word2)\n",
        "                if word2 != word:\n",
        "                    corrected.append((word, word2))\n",
        "            else:\n",
        "                words_not_found.append(word)\n",
        "                matrix[i, :300]=embeddings_ft.get(\"something\")\n",
        "                matrix[i, 300:]=embeddings_gl.get(\"something\")\n",
        "                \n",
        "    return matrix, corrected, words_not_found\n",
        "\n",
        "def build_matrix_1(nb_words, embed_size, correction_map):\n",
        "    embeddings_ft = dict(get_coefs(*o.strip().split()) for o in open(ft_path))\n",
        "    embeddings_gl = dict(get_coefs(*o.strip().split()) for o in open(gl_path))\n",
        "    embeddings_keys_ft = list(embeddings_ft.keys())\n",
        "    \n",
        "    corrected = []\n",
        "    words_not_found = []\n",
        "    matrix = np.zeros((nb_words, embed_size))\n",
        "    \n",
        "    for word, i in tqdm(word_index.items()):\n",
        "        if i >= nb_words:\n",
        "            break\n",
        "        else:\n",
        "            if embeddings_ft.get(word) is not None:\n",
        "                matrix[i, :300] = embeddings_ft.get(word)\n",
        "                if embeddings_gl.get(word) is not None:\n",
        "                    matrix[i, 300:] = embeddings_gl.get(word)\n",
        "            elif correction_map.get(word) is not None:\n",
        "                word2 = correction_map.get(word)\n",
        "                matrix[i, :300] = embeddings_ft.get(word2)\n",
        "                if embeddings_gl.get(word2) is not None:\n",
        "                    matrix[i, 300:] = embeddings_gl.get(word2)\n",
        "                corrected.append((word, word2))\n",
        "            else:\n",
        "                words_not_found.append(word)\n",
        "                matrix[i, :300]=embeddings_ft.get(\"something\")\n",
        "                matrix[i, 300:]=embeddings_gl.get(\"something\")\n",
        "        \n",
        "                \n",
        "    return matrix, corrected, words_not_found"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "JUyei26IzbVQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('../input/mapping/correction_map_final.pickle', 'rb') as handle:\n",
        "    correction_map = pickle.load(handle)\n",
        "\n",
        "print(len(correction_map))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "79SS53tEzbVa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# embedding_matrix, corrected, words_not_found = build_matrix(nb_words, embed_size)\n",
        "embedding_matrix, corrected, words_not_found = build_matrix_1(nb_words, embed_size, correction_map)\n",
        "\n",
        "print(embedding_matrix.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "4_gL5G6pzbVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(corrected))\n",
        "print(corrected)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AuXbM8SIzbVs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(words_not_found))\n",
        "print(words_not_found)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B3pCgG3rzbV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save('embedding_matrix.npy', embedding_matrix)\n",
        "\n",
        "del embedding_matrix, words_not_found, corrected\n",
        "gc.collect()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DotFElTWzbV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.load('x_train.npy')\n",
        "x_test = np.load('x_test.npy')\n",
        "y_train = np.load('y_train.npy')\n",
        "embedding_matrix = np.load('embedding_matrix.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "fQ6f_nUHzbWK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Input, Embedding, SpatialDropout1D, Bidirectional, GRU, GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, Dense, Conv1D, LSTM\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "def get_model():\n",
        "  inp = Input(shape=(maxlen, ))\n",
        "  x = Embedding(nb_words, embed_size, weights=[embedding_matrix])(inp)\n",
        "  x = SpatialDropout1D(0.5)(x)\n",
        "  x = Bidirectional(LSTM(40, return_sequences=True))(x)\n",
        "  x, x_h, x_c = Bidirectional(GRU(40, return_sequences=True, return_state=True))(x)\n",
        "  # x = Conv1D(64, kernel_size=3, padding=\"valid\", kernel_initializer=\"glorot_uniform\")(x)\n",
        "  avg_pool = GlobalAveragePooling1D()(x)\n",
        "  max_pool = GlobalMaxPooling1D()(x)\n",
        "  conc = concatenate([avg_pool, x_h, max_pool])\n",
        "  outp = Dense(6, activation=\"sigmoid\")(conc)\n",
        "  \n",
        "  model = Model(inputs=inp, outputs=outp)\n",
        "  adam = optimizers.Adam(clipvalue=1.)\n",
        "  model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "7JujZC1PzbWR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = get_model()\n",
        "\n",
        "print(model.summary())\n",
        "plot_model(model, show_shapes=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yjyKIOmXzbWZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_tra, x_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DLPwqbcxzbWe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.callbacks import Callback, ModelCheckpoint\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "class RocCallback(Callback):\n",
        "  def __init__(self, validation_data):\n",
        "    self.x_val = validation_data[0]\n",
        "    self.max_score = 0\n",
        "    self.y_val = validation_data[1]\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    y_pred_val = self.model.predict(self.x_val)\n",
        "    roc_val = roc_auc_score(self.y_val, y_pred_val)\n",
        "    print(' - Roc-auc_val: %.6f \\n' % roc_val)\n",
        "    if roc_val > self.max_score:\n",
        "      self.model.save('best_model.h5')\n",
        "      print('Saving model weights at Epoch: %d, Roc-auc_val: %.6f \\n'  % (epoch+1, roc_val))\n",
        "      self.max_score = roc_val\n",
        "    return\n",
        "\n",
        "roc = RocCallback(validation_data=(x_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0Heu6kqpzbWj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from sklearn.model_selection import KFold\n",
        "# import tensorflow.keras.backend as K\n",
        "\n",
        "# num_folds = 5\n",
        "# batch_size = 128\n",
        "# epochs = 2\n",
        "\n",
        "# predict = np.zeros((test.shape[0],6))\n",
        "# oof_predict = np.zeros((train.shape[0],6))\n",
        "# scores = []\n",
        "\n",
        "# kf = KFold(n_splits=num_folds, shuffle=True, random_state=239)\n",
        "\n",
        "# for train_index, val_index in kf.split(x_train):\n",
        "#   kf_y_train, kf_y_val = y_train[train_index], y_train[val_index]\n",
        "#   kf_x_train, kf_x_val = x_train[train_index], x_train[val_index]\n",
        "  \n",
        "#   K.clear_session()\n",
        "\n",
        "#   model = get_model()\n",
        "#   ra_val = RocCallback(validation_data=(kf_x_val, kf_y_val))\n",
        "#   model.fit(kf_x_train, kf_y_train, batch_size=batch_size, epochs=epochs, verbose=1, callbacks=[ra_val])\n",
        "\n",
        "#   model.load_weights('best_model.h5')\n",
        "#   predict += model.predict(x_test, batch_size=batch_size, verbose=1) / num_folds\n",
        "\n",
        "#   oof_predict[val_index] = model.predict(kf_x_val, batch_size=batch_size, verbose=1)\n",
        "#   cv_score = roc_auc_score(kf_y_val, oof_predict[val_index])\n",
        "#   scores.append(cv_score)\n",
        "#   print('score: ', cv_score)\n",
        "\n",
        "# print('Done')\n",
        "# print('Total CV score is %.6f' % np.mean(scores))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "v5LnGSh_zbWt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "epochs = 2\n",
        "\n",
        "hist = model.fit(x_tra, y_tra, batch_size=batch_size, callbacks=[roc], epochs=epochs, validation_data=(x_val, y_val), verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_dZr-hPSzbWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = load_model('best_model.h5')\n",
        "# model.save_weights('best_model_weights.h5')\n",
        "y_pred = model.predict(x_test, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "0BycmIlKzbW2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submid = pd.DataFrame({'id': test['id']})\n",
        "submission = pd.concat([submid, pd.DataFrame(y_pred, columns = toxicity_columns)], axis=1)\n",
        "submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}